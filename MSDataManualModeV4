import os
import pandas as pd
import glob
import re
from tqdm import tqdm

# Use 'r' to avoid path errors
DATA_FOLDER = r"C:\Users\David\Documents\School Stuff\UW Things\Classwork\ESS 469\MLGEO_Hydrothermal_Vents\masspa_2017_data" 

def parse_ooi_row(row):
    """The existing logic that works for your .dat files."""
    try:
        parts = {p.split(':')[0]: p.split(':')[1:] for p in row.split(',') if ':' in p}
        return {
            "methane_m16": float(parts['INT'][6]),
            "pressure": float(parts['PRE'][0])
        }
    except: return None

def build_2017_timeseries(root_dir):
    all_records = []
    
    # EXISTING CRAWLER: Stays exactly as is. 
    # It finds files regardless of which month folder they are in.
    files = glob.glob(os.path.join(root_dir, "**/*.dat"), recursive=True) + \
            glob.glob(os.path.join(root_dir, "**/*.txt"), recursive=True)
    
    if not files:
        print(f"‚ùå No files found in {root_dir}")
        return pd.DataFrame()

    for file in tqdm(files, desc="Crawling All Month Folders"):
        match = re.search(r'(\d{8})T(\d{4})', os.path.basename(file))
        if not match: continue
        base_ts = pd.to_datetime(match.group(1) + match.group(2), format='%Y%m%d%H%M')
        
        with open(file, 'r', errors='ignore') as f:
            chunks = f.read().split('DATA,')
            for i, chunk in enumerate(chunks):
                if 'INT:' in chunk:
                    data = parse_ooi_row(chunk)
                    if data:
                        data['timestamp'] = base_ts + pd.Timedelta(seconds=i*10)
                        all_records.append(data)
    
    df = pd.DataFrame(all_records)
    df = df.set_index('timestamp').sort_index()
    
    # 1. REMOVE DUPLICATES (Handles files with same names in different months)
    df = df[~df.index.duplicated(keep='first')]
    
    # 2. RESAMPLE TO HOURLY (Standardizes the burst data)
    df_hourly = df.resample('1h').mean()
    
    # 3. THE SEPTEMBER GAP FIX (Creates the empty rows for missing data)
    # This creates a perfect calendar for 2017
    full_year_calendar = pd.date_range(start="2017-01-01", end="2017-12-31 23:59", freq="1h")
    
    # Reindex forces the table to include every hour, filling September with NaNs
    df_final = df_hourly.reindex(full_year_calendar)
    
    return df_final

if __name__ == "__main__":
    final_df = build_2017_timeseries(DATA_FOLDER)
    
    if not final_df.empty:
        # Use .loc to access the index for September
        # This selects the 'methane_m16' column for all rows in September
        sept_data = final_df.loc['2017-09', 'methane_m16']
        
        sept_missing = sept_data.isna().sum()
        
        print(f"\n‚úÖ Processing Complete.")
        print(f"üìä September Gap Check: {sept_missing} hours of missing data identified.")
        
        final_df.to_csv("MASSPA_2017_Full_Year.csv")
        print("üíæ File saved as: MASSPA_2017_Full_Year.csv")
    else:
        print("Dataset is empty. Check your folder path.")